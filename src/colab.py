# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IJ4GdYQjx57Ph8RGzUCruVtCizmQkfcT
"""

from datetime import datetime
import time
import pandas

def main():
    start_time = time.time()
    # adding_title( "./data/ExampleTrainData(AVG)" )
    # adding_title( "./data/ExampleTrainData(IncompleteAVG)" )
    SourceData = loading_data( "./data/ExampleTrainData(AVG)" , True)

    folder_path = './data/ExampleTrainData(AVG)'

    data_pca = pca(folder_path)
    print("------------------------------")
    print( "data_pca:" )
    print( data_pca )
    print("------------------------------")

    # Already_Kmeans = KMEANS(data_pca)
    # print("------------------------------")
    # print( "Already_Kmeans:" )
    # print( Already_Kmeans )
    # print("------------------------------")

    # AllOutPut = LSTM_data( Already_Kmeans )
    AllOutPut = LSTM_data( data_pca )
    print("------------------------------")
    print( "AllOutPut:" )
    print( AllOutPut )
    print("------------------------------")
    Regression_X_train , Regression_y_train = regression_data( data_pca, SourceData )



    x_train , y_train = normal( AllOutPut , 12 )

    print("------------------------------")
    print( "x_train:" )
    print( x_train )
    print("------------------------------")

    X_train = reshape( x_train )
    print("------------------------------")
    print( "X_train:" )
    print( X_train )
    print("------------------------------")

    NowDateTime = datetime.now().strftime("%Y-%m")

    train( X_train , y_train , NowDateTime , batch_size = 128 , epochs = 100 )
    # train( x_train , y_train , NowDateTime , batch_size = 128 , epochs = 100 )

    # regression_modal( NowDateTime , AllOutPut , Regression_X_train , Regression_y_train )

    # forcast( AllOutPut = AllOutPut , lstm = './model/WheatherLSTM_' + NowDateTime + '.h5' , regression_model = './model/WheatherRegression_' + NowDateTime )

    # end_time = time.time()
    # execution_time = end_time - start_time

    # print( f"執行時間 : {execution_time}")
main()

# Commented out IPython magic to ensure Python compatibility.
# %cd drive/MyDrive/AICup

!pwd

from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.ensemble import IsolationForest

def KMEANS(data):
  kmeans = KMeans(n_clusters=3, random_state=42)
  clusters = kmeans.fit_predict(data)
  data['Cluster'] = clusters
  return clusters

import os
import numpy as np
import pandas as pd
from keras.models import load_model
from sklearn.preprocessing import MinMaxScaler
import joblib

def forcast(AllOutPut , lstm , regression_model ):
    LSTM_MinMaxModel = MinMaxScaler().fit(AllOutPut)
    regressor = load_model( lstm )
    Regression = joblib.load( regression_model )
    LookBackNum = 12
    ForecastNum = 48

    data_name = './data/ExampleTestData/upload.csv'
    source_data = pd.read_csv(data_name, encoding='utf-8')
    target = ['序號']
    ex_question = source_data[target].values
    inputs = []
    predict_output = []
    predict_power = []
    count = 0

    while count < len(ex_question):
        print('count : ', count)
        LocationCode = int(ex_question[count])
        strLocationCode = str(LocationCode)[-2:]
        if LocationCode < 10:
            strLocationCode = '0' + str(LocationCode)

        DataName = './data/ExampleTrainData(IncompleteAVG)/IncompleteAvgDATA_' + strLocationCode + '.csv'
        SourceData = pd.read_csv(DataName, encoding='utf-8')
        ReferTitle = SourceData[['Serial']].values
        ReferData = SourceData[['WindSpeed(m/s)', 'Pressure(hpa)', 'Temperature(°C)', 'Humidity(%)', 'Sunlight(Lux)']].values

        inputs = []

        for DaysCount in range(len(ReferTitle)):
            if str(int(ReferTitle[DaysCount]))[:8] == str(int(ex_question[count]))[:8]:
                TempData = ReferData[DaysCount].reshape(1, -1)
                TempData = LSTM_MinMaxModel.transform(TempData)
                inputs.append(TempData)

        for i in range(ForecastNum):
            if i > 0:
                inputs.append(predict_output[i - 1].reshape(1, 5))

            X_test = []
            X_test.append(inputs[0 + i:LookBackNum + i])

            NewTest = np.array(X_test)
            NewTest = np.reshape(NewTest, (NewTest.shape[0], NewTest.shape[1], 5))

            predicted = regressor.predict(NewTest)
            predict_output.append(predicted)
            predict_power.append(np.round(Regression.predict(predicted), 2).flatten())

        count += 48


    df = pd.DataFrame(predict_power, columns=['答案'])
    df.insert(0, '序號', ex_question )
    df.to_csv('output.csv', index=False)
    print('Output CSV File Saved')

import os
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import seaborn as sns
import matplotlib.pyplot as plt

def pca(folder_path):
  try:
    # Step 1: 定義要讀取的資料夾路徑
    # folder_path = './data/ExampleTrainData(AVG)'  # 替換為你的資料夾路徑



    # Step 2: 讀取資料夾內所有 CSV 檔案
    all_data = pd.DataFrame()  # 用於存儲所有資料的 DataFrame

    for filename in os.listdir(folder_path):
        if filename.endswith('.csv'):
            file_path = os.path.join(folder_path, filename)
            data = pd.read_csv(file_path)
            all_data = pd.concat([all_data, data], ignore_index=True)  # 合併所有資料

    # Step 3: 檢查合併後的資料內容
    print("合併後的資料：")
    print(all_data.head())
    print(all_data.info())

    # Step 4: 選擇數值欄位並處理缺失值，並排除 Power 和 Serial 欄位
    numeric_data = all_data.select_dtypes(include=['float64', 'int64']).drop(columns=['Power(mW)', 'Serial'], errors='ignore').dropna()

    print("asd")

    # Step 5: 標準化資料
    scaler = StandardScaler()
    scaled_data = scaler.fit_transform(numeric_data)

    # Step 6: 執行 PCA，降維到 2 維
    pca = PCA(n_components=2)
    data_pca = pca.fit_transform(scaled_data)

    # Step 7: 繪製 PCA 結果的散佈圖
    sns.scatterplot(x=data_pca[:, 0], y=data_pca[:, 1])
    plt.title('PCA of Combined Input Data')
    plt.xlabel('Principal Component 1')
    plt.ylabel('Principal Component 2')

    # 儲存圖表為 PNG 檔案
    output_path = 'pca_result.png'
    plt.savefig(output_path)
    print(f"圖表已儲存為 {output_path}. 請於 Windows 中打開查看。")

    # Step 8: 顯示主成分的解釋
    explained_variance = pca.explained_variance_ratio_
    print("主成分的解釋變異數比例：")
    for i, var in enumerate(explained_variance):
        print(f'主成分 {i + 1}: {var:.4f}')

    # Step 9: 顯示主成分的成分矩陣
    components = pd.DataFrame(pca.components_, columns=numeric_data.columns)
    print("\n主成分的成分矩陣：")
    print(components)
    print("aaa")
    print(data_pca)

    return data_pca

  except Exception as e:
      print(f"發生錯誤: {e}")



from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Dropout
from tensorflow.keras.models import load_model

def create_lstm_model( X_train ):
    regressor = Sequential ()

    regressor.add(LSTM(units = 128, return_sequences = True, input_shape = (X_train.shape[1], 2)))
    regressor.add(LSTM(units =  64))
    regressor.add(Dropout(0.2))

    return regressor

def output_layer_setting( regressor ):
    regressor.add(Dense(units = 5))
    regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')
    return regressor

def train( X_train , y_train , NowDateTime , epochs , batch_size):
    regressor = create_lstm_model( X_train )
    regressor = output_layer_setting( regressor )
    print("---------------------")
    print("X_train:")
    print(X_train)
    regressor.fit(X_train, y_train, epochs = epochs, batch_size = batch_size)

    from datetime import datetime
    regressor.save('./model/WheatherLSTM_' + NowDateTime+'.h5')
    print('Model Saved')

from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import MinMaxScaler
import joblib

import numpy as np
import pandas as pd
import os

def create_modal( AllOutPut , Regression_X_train , Regression_y_train ):
    LSTM_MinMaxModel = MinMaxScaler().fit(AllOutPut)
    RegressionModel = LinearRegression()
    RegressionModel.fit(LSTM_MinMaxModel.transform(Regression_X_train), Regression_y_train)
    print( "test2")
    return RegressionModel , LSTM_MinMaxModel

def regression_modal( NowDateTime , AllOutPut , Regression_X_train , Regression_y_train ):
    RegressionModel , LSTM_MinMaxModel = create_modal( AllOutPut , Regression_X_train , Regression_y_train)
    print( "test1")
    joblib.dump(RegressionModel, './model/WheatherRegression_'+NowDateTime)
    print('截距: ',RegressionModel.intercept_)

    print('係數 : ', RegressionModel.coef_)

    print('R squared: ',RegressionModel.score(LSTM_MinMaxModel.transform(Regression_X_train), Regression_y_train))

from tensorflow.keras.layers import LSTM
from sklearn.preprocessing import MinMaxScaler
import numpy as np

def normal( AllOutPut , LookBackNum , ):
    LSTM_MinMaxModel = MinMaxScaler().fit(AllOutPut)
    AllOutPut_MinMax = LSTM_MinMaxModel.transform(AllOutPut)

    X_train = []
    y_train = []

    for i in range(LookBackNum,len(AllOutPut_MinMax)):
        X_train.append(AllOutPut_MinMax[i-LookBackNum:i, :])
        y_train.append(AllOutPut_MinMax[i, :])


    X_train = np.array(X_train)
    y_train = np.array(y_train)

    return X_train , y_train

def reshape( X_train ):
    print( X_train.shape[0] )
    print( X_train.shape[1] )
    return np.reshape(X_train,(X_train.shape [0], X_train.shape [1], 2))

def regression_data( data_pca, SourceData ):
    # Regression_X_train = sourceData[['WindSpeed(m/s)','Pressure(hpa)','Temperature(°C)','Humidity(%)','Sunlight(Lux)']].values
    # Regression_y_train = sourceData[['Power(mW)']].values
    # print( type(sourceData) )
    Regression_X_train = data_pca
    # print( Regression_X_train )
    Regression_y_train = SourceData
    return ( Regression_X_train , Regression_y_train )

def LSTM_data( data_pca ):
    # return sourceData[['WindSpeed(m/s)','Pressure(hpa)','Temperature(°C)','Humidity(%)','Sunlight(Lux)']].values
    return data_pca

def loading_data( sourceFile = "./data/ExampleTrainData(AVG)" , flag = True) :
    if flag == False :
        DataName = sourceFile
        SourceData = pd.read_csv(DataName, encoding='utf-8')
        return SourceData
    else:
        file_names = os.listdir( sourceFile )
        all = []
        for file_name in file_names:
            if file_name.endswith('.csv'):
                file_path = os.path.join(sourceFile, file_name)
                df = pd.read_csv(file_path, encoding='utf-8')
                all.append(df)
        combined_data = pd.concat(all, ignore_index=True)
        return combined_data

import pandas as pd
import os

def getting_title( sourceCode ):
    f = open( sourceCode + "/Title.txt" , "r" , encoding = 'utf-8' )
    get = f.read()
    f.close()
    return get

def adding_title( sourceFile ):
    file_names = os.listdir( sourceFile )
    for file_name in file_names:
        if file_name.endswith('.csv'):
            with open( sourceFile + "/" + file_name , 'r' ) as f:
                get = f.read()
            with open( sourceFile + "/" + file_name , 'w' , encoding = 'utf-8') as fileWrite:
                fileWrite.write( getting_title( sourceFile ) + '\n' + get)
                print( getting_title( sourceFile ) )

from google.colab import drive
drive.mount('/content/drive')

